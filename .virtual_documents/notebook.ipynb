import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import time

np.random.seed(42)


def sigmoid(x):
    value = 1/(1+np.exp(-x))
    return value

def sigmoid_deravative(x):
    value = x*(1-x)
    return value


class XORNet:
    def __init__(self, input_size, hidden_size, output_size):
        self.W1 = np.random.uniform(size=(input_size, hidden_size))
        self.b1 = np.random.uniform(size=(1, hidden_size))
        
        self.W2 = np.random.uniform(size=(hidden_size, output_size))
        self.b2 = np.random.uniform(size=(1, output_size))
        
    def forward(self, X):
        # --- Layer 1 ---
        self.h1 = np.dot(X, self.W1) + self.b1
        
        self.a1 = sigmoid(self.h1)
        
        # --- Layer 2 ----
        
        self.h2 = np.dot(self.a1, self.W2) + self.b2 
        self.y_hat = sigmoid(self.h2)
        
        return self.y_hat
    
    def backward(self,X, y, lr ):
        
        delta_out = (self.y_hat-y) * sigmoid_deravative(self.y_hat)
        
        # dc/da1
        error_hidden = delta_out.dot(self.W2.T) 
        
        
        delta_hidden = error_hidden * sigmoid_deravative(self.a1)
        
        dw2 = self.a1.T.dot(delta_out) 
        
        dw1 = X.T.dot(delta_hidden)
        
        # Update the weights
        
        self.W2 = self.W2 - lr*dw2
        self.W1 = self.W1 - lr*dw1
        
        # Update the bias
        self.b2 = self.b2 - lr*np.sum(delta_out, axis=0, keepdims=True)
        self.b1 = self.b1 - lr*np.sum(delta_hidden, axis=0, keepdims=True)
        
 
        
         





X = np.array([[0,0], [0,1], [1,0], [1,1]])
y = np.array([[0], [1], [1], [0]])

nn = XORNet(input_size=2, hidden_size=2, output_size=1)

loss_history = []
epochs = 50000
learning_rate = 0.1

start_time = time.time()


print("Starting  Training....")

for i in range(epochs):
    # Forward Pass
    nn.forward(X)
    
    # Backward Pass
    
    nn.backward(X, y, lr=learning_rate)
    
    # Calculate the loss
    loss = np.mean(np.square(y-nn.y_hat))
    loss_history.append(loss)
    
    if i % 1000 == 0:
        print(f"Epoch {i}: Loss {loss:.4f}")
        
end_time = time.time()
print(f"\nTraining Complete in {end_time - start_time:.2f} seconds.")
        

print(nn.forward(X))

# Plot Loss Curve
plt.plot(loss_history)
plt.title("Training Loss")
plt.xlabel("Epoch")
plt.ylabel("Error")
plt.show()
      
    
    




